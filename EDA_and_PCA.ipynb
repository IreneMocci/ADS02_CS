{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write a function that can generate the following sequences:\n",
    "   * sequence #1: 2 * n + 1\n",
    "   * sequence #2: 50 - 5 * n\n",
    "   * sequence #3: 2 ** n\n",
    "\n",
    "Although this exercises can easily be done with list comprehensions, it can be more efficient to use numpy\n",
    "(the arange method can be handy here).\n",
    "\n",
    "Start by generating all 50 first values for the sequence that was selected by sequence_number and return a numpy array filtered so that it only contains values in [min_value, max_value] (min and max being included)\n",
    "\n",
    "* param min_value: minimum value to use to filter the arrays\n",
    "* param max_value: maximum value to use to filter the arrays\n",
    "* param sequence_number: number of the sequence to return\n",
    "* returns: the right sequence as a np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 32])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_sequences(min_value, max_value, sequence_number):\n",
    "    \n",
    "    n = np.arange(50)\n",
    "    if sequence_number == 1:\n",
    "        seq = 2*n + 1\n",
    "    elif sequence_number == 2:\n",
    "        seq = 50 - 5*n\n",
    "    elif sequence_number == 3:\n",
    "        seq = 2**n\n",
    "    seq_min = seq[seq >= min_value]\n",
    "    result = seq_min[seq_min <= max_value]\n",
    "    return result\n",
    "\n",
    "min_value = 15\n",
    "max_value = 37\n",
    "sequence_number = 3\n",
    "build_sequences(min_value, max_value, sequence_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Given a numpy vector x of n > k, compute the moving averages\n",
    "of length k.  In other words, return a vector z of length\n",
    "m = n - k + 1 where z_i = mean([x_i, x_i-1, ..., x_i-k+1])\n",
    "\n",
    "Note that z_i refers to value of z computed from index i of x,\n",
    "but not z index i. z will be shifted compared to x \n",
    "since it cannot be computed for the first k-1 values of x.\n",
    "\n",
    "Example inputs:\n",
    "* x = [1, 2, 3, 4]\n",
    "* k = 3\n",
    "\n",
    "the moving average of 3 is only defined for the last 2\n",
    "values: [3, 4].\n",
    "* z = np.array([mean([1,2,3]), mean([2,3,4])])\n",
    "* z = np.array([2.0, 3.0])\n",
    "\n",
    "\n",
    "* param x: numpy array of dimension n > k\n",
    "* param k: length of the moving average\n",
    "* returns: a numpy array z containing the moving averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def moving_averages(x, k):\n",
    "    r = np.cumsum(x)\n",
    "    r[k:] = r[k:] - r[: - k]\n",
    "    result = r[k - 1:] / k\n",
    "    return result\n",
    "\n",
    "x = np.array([1, 2, 3, 4])\n",
    "k = 3\n",
    "moving_averages(x, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Given two numpy matrices A and B of arbitrary dimensions, return a new numpy matrix of the following form:\n",
    "        ([A,0], [0,B])\n",
    "\n",
    "Example inputs:\n",
    "      A = ([1,2], [3,4])    \n",
    "      B = ([5,6], [7,8])\n",
    "\n",
    "Expected output:\n",
    "        ([1,2,0,0],\n",
    "        [3,4,0,0],\n",
    "        [0,0,5,6],\n",
    "        [0,0,7,8])\n",
    "\n",
    "* param A: numpy array\n",
    "* param B: numpy array\n",
    "* returns: a numpy array with A and B on the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 0., 0.],\n",
       "       [3., 4., 0., 0.],\n",
       "       [0., 0., 5., 6.],\n",
       "       [0., 0., 7., 8.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block_matrix(A, B):   \n",
    "    za_matr = np.zeros((B.shape[0], A.shape[1]))\n",
    "    zb_matr = np.zeros((A.shape[0], B.shape[1]))\n",
    "    az_matr = np.vstack((A, za_matr))\n",
    "    bz_matr = np.vstack((zb_matr, B))\n",
    "    ab_matr = np.hstack((az_matr, bz_matr))\n",
    "    return ab_matr\n",
    "\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "block_matrix(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write a function that takes a pandas.DataFrame with four columns: \"category\", \"price\", \"weight\", \"in_stock\" and returns a pandas.Series containing the price of the heaviest weight per category of items still in stock.\n",
    "\n",
    "You can assume that no items in the same category have the same weight to make things simpler to reason about.\n",
    "The returned Series should not have an index name and the values should be sorted in descending order.\n",
    "You should return an empty Series if there are not items in stock for all categories.\n",
    "\n",
    "Example input:\n",
    "\n",
    "        category      price weight  in_stock\n",
    "    0   electronics   400   740     False\n",
    "    1   health        5     100     False\n",
    "    2   electronics   300   6000    True\n",
    "    3   books         20    300     True\n",
    "\n",
    "Note: entries of in_stock are booleans.\n",
    "\n",
    "Expected output:\n",
    "\n",
    "    electronics    300\n",
    "    books          20\n",
    "    dtype: int64\n",
    "\n",
    "* :param inventory: pandas.DataFrame with four column \"category\", \"price\", \"weight\", \"in_stock\"\n",
    "* :return: a pandas.Series with the category as index and the selected prices in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electronics    300\n",
      "books           20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_prices_for_heaviest_item(inventory):\n",
    "    available = inventory.loc[inventory['in_stock']==True]\n",
    "    max_prices = available['price'].groupby(inventory['category']).max().sort_values(ascending=False)\n",
    "    categ_price =  pd.Series(index=max_prices.index.values, data=max_prices.values)\n",
    "    return categ_price\n",
    "\n",
    "inventory = pd.DataFrame({'category': {0: 'electronics', 1: 'health' , 2: 'electronics', 3: 'books'}, 'price': {0: 400, 1: 5, 2: 300, 3: 20}, 'weight': {0: 740, 1: 100, 2: 6000, 3: 300}, 'in_stock': {0: False, 1: False, 2: True, 3: True}})\n",
    "categ_price = get_prices_for_heaviest_item(inventory)\n",
    "print(categ_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write a function that takes a pandas.DataFrame with 7 columns:\"location\", 'Jan-2018', 'Feb-2018', 'Mar-2018', \"April-2018\", \"May-2018\", \"June-2018\".\n",
    "This DataFrame represents temperature measurements in the first two quarters of 2018 for a particular city.\n",
    "This function should return a new DataFrame containing three columns: \"location\", \"Date\", \"Value\" and where each row represents a measurement in particular location at a particular date.\n",
    "The returned pandas.DataFrame should sort the values by location first and then by temperature measurement.\n",
    "It should also drop any missing values and reset the index of the returned DataFrame.\n",
    "\n",
    "NOTE: If measurements is empty your function should return and empty dataframe:\n",
    "      location       date   value\n",
    "\n",
    "Example input:\n",
    "\n",
    "       location  Jan-2018  Feb-2018  Mar-2018  April-2018  May-2018  June-2018\n",
    "    0  Brussels         2         3         8        12.0        14         17\n",
    "    1     Paris         2         3         9         NaN        15         18\n",
    "\n",
    "Expected output:\n",
    "\n",
    "        location        date  value\n",
    "    0   Brussels    Jan-2018    2.0\n",
    "    1   Brussels    Feb-2018    3.0\n",
    "    2   Brussels    Mar-2018    8.0\n",
    "    3   Brussels  April-2018   12.0\n",
    "    4   Brussels    May-2018   14.0\n",
    "    5   Brussels   June-2018   17.0\n",
    "    6      Paris    Jan-2018    2.0\n",
    "    7      Paris    Feb-2018    3.0\n",
    "    8      Paris    Mar-2018    9.0\n",
    "    9      Paris    May-2018   15.0\n",
    "    10     Paris   June-2018   18.0\n",
    "\n",
    "* :param measurements: pandas.DataFrame with seven columns:\n",
    "    \"location\", 'Jan-2018', 'Feb-2018', 'Mar-2018', \"April-2018\", \"May-2018\", \"June-2018\"\n",
    "* :return: a pandas.DataFrame containing three columns \"location\", \"date\", \"value\" with a row\n",
    "    for each temperature measurement in a given location. There should be no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brussels</td>\n",
       "      <td>Jan-2018</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brussels</td>\n",
       "      <td>Feb-2018</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brussels</td>\n",
       "      <td>Mar-2018</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brussels</td>\n",
       "      <td>April-2018</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brussels</td>\n",
       "      <td>May-2018</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brussels</td>\n",
       "      <td>June-2018</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Paris</td>\n",
       "      <td>Jan-2018</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Paris</td>\n",
       "      <td>Feb-2018</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Paris</td>\n",
       "      <td>Mar-2018</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Paris</td>\n",
       "      <td>May-2018</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Paris</td>\n",
       "      <td>June-2018</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location        date  value\n",
       "0   Brussels    Jan-2018    2.0\n",
       "1   Brussels    Feb-2018    3.0\n",
       "2   Brussels    Mar-2018    8.0\n",
       "3   Brussels  April-2018   12.0\n",
       "4   Brussels    May-2018   14.0\n",
       "5   Brussels   June-2018   17.0\n",
       "6      Paris    Jan-2018    2.0\n",
       "7      Paris    Feb-2018    3.0\n",
       "8      Paris    Mar-2018    9.0\n",
       "9      Paris    May-2018   15.0\n",
       "10     Paris   June-2018   18.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reshape_temperature_data(measurements):\n",
    "    df = pd.melt(measurements, id_vars=['location'], var_name='date', value_name='value')\n",
    "    df = df.dropna()\n",
    "    df_new = df.sort_values(by=['location','value'])\n",
    "    d_indx = df_new.reset_index(drop=True)\n",
    "    return d_indx\n",
    "\n",
    "measurements = pd.DataFrame({'location': {0: 'Brussels', 1: 'Paris'}, 'Jan-2018': {0: 2, 1: 2}, 'Feb-2018': {0: 3, 1: 3}, 'Mar-2018': {0: 8, 1: 9}, 'April-2018': {0: 12.0, 1: np.nan}, 'May-2018': {0: 14, 1: 15}, 'June-2018': {0: 17, 1:18}})\n",
    "reshape_temperature_data(measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write a function that takes a pandas.DataFrame containing 2 columns representing web events for a user: \"user_id\" and \"event\".\n",
    "This function should return a new DataFrame where each event value becomes a new column in the returned DataFrame.\n",
    "We expect the columns (events) to be in alphabetical order.\n",
    "\n",
    "For each event value, you need to calculate the count of that particular event for each userid.\n",
    "Missing values should be filled with 0.\n",
    "Effectively, this function calculates the number of occurrence for each event type (columns) for each user (rows).\n",
    "You should return an empty Series if the input DataFrame is empty.\n",
    "\n",
    "Example input:\n",
    "\n",
    "        user_id\tevent\n",
    "    0\t1234\tclick\n",
    "    1\t4321\tclick\n",
    "    2\t1234\tclick\n",
    "    3\t1234\tplay\n",
    "    4\t4321\tplay\n",
    "    5\t3456\tpause\n",
    "\n",
    "Expected output:\n",
    "\n",
    "        \tclick\tpause\tplay\n",
    "    1234\t2.0\t    0.0\t    1.0\n",
    "    3456\t0.0\t    1.0\t    0.0\n",
    "    4321\t1.0\t    0.0\t    1.0\n",
    "\n",
    "* :param events: pandas.DataFrame with two columns: \"user_id\" and \"event\"\n",
    "* :return: a pandas.DataFrame returning the number of occurrence for each event type (columns) for each user (rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>event</th>\n",
       "      <th>click</th>\n",
       "      <th>pause</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "event    click  pause  play\n",
       "user_id                    \n",
       "1234         2      0     1\n",
       "3456         0      1     0\n",
       "4321         1      0     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_events_matrix_count(events):\n",
    "    if events.empty:\n",
    "        return pd.Series()\n",
    "    else:\n",
    "        result = pd.pivot_table(events, index='user_id', columns='event', aggfunc=len, fill_value=0)\n",
    "        return result\n",
    "\n",
    "events = pd.DataFrame({'user_id': {0: 1234, 1: 4321, 2: 1234, 3: 1234, 4: 4321, 5: 3456}, 'event': {0: 'click', 1: 'click', 2: 'click', 3: 'play', 4: 'play', 5: 'pause'}})\n",
    "compute_events_matrix_count(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write a function that takes a pandas DataFrame with two columns \"time_1\" and \"time_2\" of UNIX timestamps given in seconds (you will need to specify the unit if using pd.to_datetime).\n",
    "\n",
    "The function should return a new dataFrame with one single column \"difference_days\" consisting of the absolute difference in days between time_1 and time_2.\n",
    "\n",
    "Example input:\n",
    "\n",
    "               time_1      time_2\n",
    "        0  1456694829  1455845363\n",
    "\n",
    "Here we have a single row for which time_1 corresponds to 28/02/2016 and time_2 to 19/02/2016.\n",
    "\n",
    "Expected output:\n",
    "    \n",
    "           difference_days\n",
    "        0                9\n",
    "    \n",
    "Hint:\n",
    "Take special care on how negative timedeltas are treated in Python.\n",
    "Getting the number of days directly from a negative timedelta might\n",
    "    not give you the result you expect.\n",
    "\n",
    "* :param df: DataFrame with the two columns of timestamps\n",
    "* :return: new dataframe with differences in days between timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difference_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   difference_days\n",
       "0                9\n",
       "1               62\n",
       "2               60\n",
       "3              153"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diff_in_days(df):\n",
    "    df['time_1'] = pd.to_datetime(df['time_1'], unit='s', dayfirst=True)\n",
    "    df['time_2'] = pd.to_datetime(df['time_2'], unit='s', dayfirst=True)\n",
    "    df['difference_days'] = (abs(df['time_1'] - df['time_2'])).dt.days\n",
    "    days = pd.DataFrame(df['difference_days'], columns=['difference_days'])\n",
    "    return days\n",
    "\n",
    "df = pd.DataFrame({'time_1': {0: 1456694829, 1: 1480946454, 2: 1451606400, 3: 1472688000}, 'time_2': {0: 1455845363, 1: 1475568868, 2: 1456790400, 3: 1485907200}})\n",
    "diff_in_days(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write a function that takes a pandas DataFrame with one column, locations, containing information about a specific location. The info is stored in a string that can be loaded as a json object.\n",
    "The function should return a DataFrame with one column, \"short_name\" that contains the value associated with the key \"short_name\" for each row.\n",
    "\n",
    "Note: you can assume all strings are exactly in the format given below though possibly longer and with different keys.\n",
    "\n",
    "Example input:\n",
    "                                              locations\n",
    "        0  {\"short_name\": \"Detroit, MI\", \"id\": 2391585}\n",
    "        1    {\"short_name\": \"Tracy, CA\", \"id\": 2507550}\n",
    "\n",
    "Where each value is a string such as:\n",
    "    \n",
    "       '{\"short_name\": \"Detroit, MI\", \"id\": 2391585}'\n",
    "\n",
    "Expected output:\n",
    "    \n",
    "            short_name\n",
    "        0  Detroit, MI\n",
    "        1    Tracy, CA\n",
    "\n",
    "Hint: you might want to use json.loads from the json library together with .apply from pandas to extract the correct key from the json object.\n",
    "\n",
    "* :param df: DataFrame with the locations column\n",
    "* :return: new DataFrame with the short_name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detroit, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tracy, CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    short_name\n",
       "0  Detroit, MI\n",
       "1    Tracy, CA"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_location(df):\n",
    "    df_new = df.join(df['locations'].apply(json.loads).apply(pd.Series))\n",
    "    result = pd.DataFrame(df_new['short_name'], columns=['short_name'])\n",
    "    return result\n",
    "\n",
    "df = pd.DataFrame({'locations': {0:'{\"short_name\": \"Detroit, MI\", \"id\": 2391585}', 1: '{\"short_name\": \"Tracy, CA\", \"id\": 2507550}'}})\n",
    "return_location(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write a function that takes a pandas DataFrame with one column, text, that contains an arbitrary text. The function should extract all post-codes that appear in that text and concatenate them together with \" | \". The result is a new dataframe with a column \"postcodes\" that contains all concatenated\n",
    "postcodes.\n",
    "\n",
    "Example input:\n",
    "    \n",
    "       text\n",
    "    0  Great Doddington, Wellingborough NN29 7TA, UK\\nTaylor, Leeds LS14 6JA, UK\n",
    "    1  This is some text, and here is a postcode CB4 9NE\n",
    "\n",
    "Expected output:\n",
    "\n",
    "                postcodes\n",
    "    0  NN29 7TA | LS14 6JA\n",
    "    1              CB4 9NE\n",
    "\n",
    "Note: Postcodes, in the UK, are of one of the following form where `X` means a letter appears and `9` means a number appears:\n",
    "\n",
    "    X9 9XX\n",
    "    X9X 9XX\n",
    "    X99 9XX\n",
    "    XX9 9XX\n",
    "    XX9X 9XX\n",
    "    XX99 9XX\n",
    "\n",
    "Even though the standard layout is to include one single space in between the two halves of the post code, there are occasional formating\n",
    "errors where an arbitrary number of space is included (0, 1, or more). You should parse those codes as well.\n",
    "\n",
    "* :param df: a DataFrame with the text column\n",
    "* :return: new DataFrame with the postcodes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postcodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN29 7TA | LS14 6JA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB4 9NE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             postcodes\n",
       "0  NN29 7TA | LS14 6JA\n",
       "1              CB4 9NE"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_post_codes(df):\n",
    "    regex = r'([A-Z]{1,2}\\d{1,2}([A-Z]{1})?\\s{0,}\\d{1}[A-Z]{2})'\n",
    "    postcodes = df['text'].str.extractall(regex)\n",
    "    postcodes = postcodes.dropna(axis=1)\n",
    "    post = pd.DataFrame()\n",
    "    for row_index in range(len(df)):\n",
    "        val = postcodes.loc[row_index].astype(str).apply(' | '.join, axis=0)\n",
    "        post = post.append(val, ignore_index=True)\n",
    "    post.columns = ['postcodes']\n",
    "    return post\n",
    "\n",
    "df = pd.DataFrame({'text': {0: 'Great Doddington, Wellingborough NN29 7TA, UK\\nTaylor, Leeds LS14 6JA, UK', 1: 'This is some text, and here is a postcode CB4 9NE'}})\n",
    "return_post_codes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Take a DataFrame and return one where all occurrences of the replacement string have been replaced by `np.nan` and, subsequently, all rows containing np.nan have been removed.\n",
    "\n",
    "Example with replacement_str='blah'\n",
    "    \n",
    "         A       B      C                   A     B    C\n",
    "    --------------------------         ------------------\n",
    "    0 |  0.5 |  0.3   | 'blah'         1 | 0.2 | 0.1 | 5\n",
    "    1 |  0.2 |  0.1   |   5     -->    3 | 0.7 | 0.2 | 1\n",
    "    2 |  0.1 | 'blah' |   3\n",
    "    3 |  0.7 |  0.2   |   1\n",
    "\n",
    "Note: keep the original index (not reset)\n",
    "\n",
    "* :param df: Input data frame (pandas.DataFrame)\n",
    "* :param replacement_str: string to find and replace by np.nan\n",
    "* :returns: DataFrame where the occurences of replacement_str have been replaced by np.nan and subsequently all rows containing np.nan have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C\n",
       "1  0.2  0.1  5.0\n",
       "3  0.7  0.2  1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nan_processor(df, replacement_str):\n",
    "    row_nan = df.replace(replacement_str, np.nan)\n",
    "    result = row_nan.dropna()\n",
    "    return result\n",
    "\n",
    "df = pd.DataFrame({'A': [0.5, 0.2, 0.1, 0.7], 'B': [0.3, 0.1, 'blah', 0.2], 'C': ['blah', 5, 3, 1]})\n",
    "replacement_str = 'blah'\n",
    "nan_processor(df, replacement_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Take a dataframe where columns are all numerical and non-constant. \n",
    "For each feature, mark the values that are not between the given percentiles (low-high) as np.nan. If a value is exactly on the high or low percentile, it should be marked as nan too.\n",
    "\n",
    "Then, remove all rows containing np.nan.\n",
    "Finally, the columns must be scaled to have zero mean and unit variance (do this without sklearn).\n",
    "\n",
    "Example testdf:\n",
    "    \n",
    "            0     1     2\n",
    "    ---------------------\n",
    "    A |   0.1   0.2   0.1\n",
    "    B |   5.0  10.0  20.0\n",
    "    C |   0.2   0.3   0.5\n",
    "    D |   0.3   0.2   0.7\n",
    "    E |  -0.1  -0.2  -0.4\n",
    "    F |   0.1   0.4   0.3\n",
    "    G |  -0.5   0.3  -0.2\n",
    "    H | -10.0   0.3   1.0\n",
    "\n",
    "Output of feature_cleaner(testdf, 0.01, 0.99):\n",
    "\n",
    "                0         1         2\n",
    "    ---------------------------------\n",
    "    A |  0.191663 -0.956183 -0.515339\n",
    "    C |  0.511101  0.239046  0.629858\n",
    "    D |  0.830540 -0.956183  1.202457\n",
    "    F |  0.191663  1.434274  0.057260\n",
    "    G | -1.724967  0.239046 -1.374236\n",
    "\n",
    "* :param df:      Input DataFrame (with numerical columns)\n",
    "* :param low:     Lowest percentile  (0.0<low<1.0)\n",
    "* :param high:    Highest percentile (low<high<1.0)\n",
    "* :returns:       Scaled DataFrame where elements that are outside of the desired percentile range have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.191663</td>\n",
       "      <td>-0.956183</td>\n",
       "      <td>-0.515339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.511101</td>\n",
       "      <td>0.239046</td>\n",
       "      <td>0.629858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.830540</td>\n",
       "      <td>-0.956183</td>\n",
       "      <td>1.202457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.191663</td>\n",
       "      <td>1.434274</td>\n",
       "      <td>0.057260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>-1.724967</td>\n",
       "      <td>0.239046</td>\n",
       "      <td>-1.374236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "A  0.191663 -0.956183 -0.515339\n",
       "C  0.511101  0.239046  0.629858\n",
       "D  0.830540 -0.956183  1.202457\n",
       "F  0.191663  1.434274  0.057260\n",
       "G -1.724967  0.239046 -1.374236"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_cleaner(df, low, high):\n",
    "    def remove_outliers(df):\n",
    "        perc_min = df.quantile(low)\n",
    "        perc_max = df.quantile(high)\n",
    "        filtered = df[(perc_min < df) & (df < perc_max)]\n",
    "        return filtered\n",
    "    df = df.apply(remove_outliers)\n",
    "    df = df.dropna()\n",
    "    normalized_df = (df - df.mean())/df.std()\n",
    "    return normalized_df\n",
    "\n",
    "df = pd.DataFrame({'0': [0.1, 5.0, 0.2, 0.3, -0.1, 0.1, -0.5, -10.0], '1': [0.2, 10.0, 0.3, 0.2, -0.2, 0.4, 0.3, 0.3], '2': [0.1, 20.0, 0.5, 0.7, -0.4, 0.3, -0.2, 1.0]}, index=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "low = 0.01\n",
    "high = 0.99\n",
    "feature_cleaner(df, low, high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Take a dataframe where all columns are numerical (no NaNs) and not constant.\n",
    "One of the column named \"CLASS\" is either 0 or 1.\n",
    "\n",
    "Within each class, for each feature compute the ratio (R) of the range over the variance (the range is the gap between the smallest and largest value).\n",
    "\n",
    "For each feature you now have two R; R_0 and R_1 where:\n",
    "R_0 = (max_class0 - min_class0) / variance_class0\n",
    "\n",
    "For each column, compute the ratio (say K) of the larger R to the smaller R.\n",
    "Return the name of the column for which this last ratio K is largest.\n",
    "\n",
    "Test input\n",
    "    \n",
    "           A     B     C    CLASS\n",
    "    ---------------------------------\n",
    "    0 |   0.1   0.2   0.1     0\n",
    "    1 |   5.0  10.0  20.0     0\n",
    "    2 |   0.2   0.3   0.5     1\n",
    "    3 |   0.3   0.2   0.7     0\n",
    "    4 |  -0.1  -0.2  -0.4     1\n",
    "    5 |   0.1   0.4   0.3     0\n",
    "    6 |  -0.5   0.3  -0.2     0\n",
    "\n",
    "Expected output: 'C'\n",
    "\n",
    "* :param df:  Input DataFrame (with numerical columns)\n",
    "* :returns:   Name of the column with largest K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_feature(df):    \n",
    "    df_group = (df.groupby(df['CLASS']).max() - df.groupby(df['CLASS']).min())/df.groupby(df['CLASS']).var()\n",
    "    ind = (df_group.max()/df_group.iloc[:])\n",
    "    max_ind = ind.max().idxmax()\n",
    "    return max_ind\n",
    "\n",
    "df = pd.DataFrame({'A': [0.1, 5.0, 0.2, 0.3, -0.1, 0.1, -0.5], 'B': [0.2, 10.0, 0.3, 0.2, -0.2, 0.4, 0.3], 'C': [0.1, 20.0, 0.5, 0.7, -0.4, 0.3, -0.2], 'CLASS': [0, 0, 1, 0, 1, 0, 0]})\n",
    "get_feature(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write a function that takes in a label to encode and a list of possible\n",
    "labels. It should return the label one-hot-encoded as a list of elements\n",
    "containing 0s and a unique 1 at the index corresponding to the matching\n",
    "label. Note that the input list of labels should contain unique elements.\n",
    "If the label does not appear in our known labels, return a list of 0s.\n",
    "\n",
    "Examples:\n",
    "    \n",
    "    one_hot_encode(\"pink\", [\"blue\", \"red\", \"pink\", \"yellow\"]) -> [0, 0, 1, 0]\n",
    "    one_hot_encode(\"b\", [\"a\", \"b\", \"c\", \"d\", \"e\"]) -> [0, 1, 0, 0, 0]\n",
    "    one_hot_encode(\"f\", [\"a\", \"b\", \"c\", \"d\", \"e\"]) -> [0, 0, 0, 0, 0]\n",
    "\n",
    "* :param label_to_encode: the label to encode\n",
    "* :param labels: a list of all possible labels\n",
    "* :return: a list of 0s and one 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encode(label_to_encode, labels):\n",
    "    \n",
    "    encode = []\n",
    "    for _, lab in enumerate(labels):\n",
    "        if lab == label_to_encode:\n",
    "            enc_lab = 1\n",
    "        else:\n",
    "            enc_lab = 0\n",
    "        encode.append(enc_lab)\n",
    "    return encode\n",
    "\n",
    "one_hot_encode(\"pink\", [\"blue\", \"red\", \"pink\", \"yellow\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains a set of functions to implement using PCA.\n",
    "All of them take at least a dataframe df as argument. To test your functions\n",
    "locally, we recommend using the wine dataset that you can load from sklearn by\n",
    "importing sklearn.datasets.load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "df_wine = pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Apply PCA on a DataFrame and return a new DataFrame containing\n",
    "the cumulated explained variance from with only the first component,\n",
    "up to using all components together. Values should be expressed as\n",
    "a percentage of the total variance explained.\n",
    "\n",
    "The DataFrame will have one row and each column should correspond to a \n",
    "principal component.\n",
    "\n",
    "Example:\n",
    "   \n",
    "             PC1        PC2        PC3        PC4    PC5\n",
    "    0  36.198848  55.406338  66.529969  73.598999  100.0\n",
    "\n",
    "If scale is True, you should standardise the data first\n",
    "\n",
    "* :param df: pandas DataFrame\n",
    "* :param scale: boolean, whether to scale or not\n",
    "* :return: a new DataFrame with cumulated variance in percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumulated_variance(df, scale):    \n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        df = pd.DataFrame(scaler.fit_transform(df))\n",
    "    pca = PCA()\n",
    "    pca.fit(df)\n",
    "    a_matr = pca.fit_transform(df)\n",
    "    covariance = np.cov(a_matr.T)\n",
    "    expl_variance = pca.explained_variance_/np.sum(pca.explained_variance_)\n",
    "    cum_expl_ratio = np.cumsum(pca.explained_variance_ratio_)*100\n",
    "    data = cum_expl_ratio.reshape(1, cum_expl_ratio.shape[0])\n",
    "    cols= ','.join([\"PC%d\" %i for i in range(1, cum_expl_ratio.shape[0] + 1)])\n",
    "    cols = cols.split(',')\n",
    "    df_PCAs = pd.DataFrame(data, columns = cols)\n",
    "    return df_PCAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine dataframe\n",
    "scale = 'True'\n",
    "get_cumulated_variance(df_wine, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Apply PCA on a given DataFrame df and return a new DataFrame containing the coordinates of the first two principal components expressed in the original basis (with the original columns).\n",
    "\n",
    "Example: if the original DataFrame was:\n",
    "\n",
    "          A    B\n",
    "    0   1.3  1.2\n",
    "    1  27.0  2.1\n",
    "    2   3.3  6.8\n",
    "    3   5.1  3.2\n",
    "\n",
    "we want the components PC1 and PC2 expressed as a linear combination of A and B, presented in a table as:\n",
    "\n",
    "              A      B\n",
    "    PC1    0.99  -0.06\n",
    "    PC2    0.06   0.99\n",
    "\n",
    "If scale is True, you should standardise the data first\n",
    "\n",
    "* :param df: pandas DataFrame\n",
    "* :param scale: boolean, whether to scale or not\n",
    "* :return: a new DataFrame with coordinates of PC1 and PC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_of_first_two(df, scale):\n",
    "    cols = df.columns\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        df = pd.DataFrame(scaler.fit_transform(df))\n",
    "    pca = PCA()\n",
    "    pca.fit(df)\n",
    "    w_sub = pca.components_\n",
    "    w_pca = w_sub[0:2, :]\n",
    "    rows= ','.join([\"PC%d\" %i for i in range(1, 3)])\n",
    "    rows = rows.split(',')\n",
    "    df_new = pd.DataFrame(w_pca, columns=cols, index=rows)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>0.998183</td>\n",
       "      <td>-0.060256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>0.060256</td>\n",
       "      <td>0.998183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B\n",
       "PC1  0.998183 -0.060256\n",
       "PC2  0.060256  0.998183"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample dataframe\n",
    "df = pd.DataFrame({'A': [1.3, 27, 3.3, 5.1], 'B': [1.2, 2.1, 6.8, 3.2]}) \n",
    "scale = False\n",
    "get_coordinates_of_first_two(df, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>0.001659</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>-0.004671</td>\n",
       "      <td>0.017868</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.999823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.026450</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.001354</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>-0.000763</td>\n",
       "      <td>-0.003495</td>\n",
       "      <td>-0.017774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
       "PC1  0.001659   -0.000681  0.000195          -0.004671   0.017868   \n",
       "PC2  0.001203    0.002155  0.004594           0.026450   0.999344   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "PC1       0.000990    0.001567             -0.000123         0.000601   \n",
       "PC2       0.000878   -0.000052             -0.001354         0.005004   \n",
       "\n",
       "     color_intensity       hue  od280/od315_of_diluted_wines   proline  \n",
       "PC1         0.002327  0.000171                      0.000705  0.999823  \n",
       "PC2         0.015100 -0.000763                     -0.003495 -0.017774  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wine dataframe\n",
    "scale = False\n",
    "get_coordinates_of_first_two(df_wine, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Apply PCA on a given DataFrame df and use it to determine the 'most important' features in your dataset. To do so we will focus on the principal component that exhibits the highest explained variance (that's PC1).\n",
    "\n",
    "PC1 can be expressed as a vector with weight on each of the original columns. Here we want to return the names of the two features that\n",
    "have the highest weights in PC1 (in absolute value).\n",
    "\n",
    "Example: if the original DataFrame was:\n",
    "\n",
    "          A    B     C\n",
    "     0  1.3  1.2   0.1\n",
    "     1  2.0  2.1   1.2\n",
    "     2  3.3  6.8  23.4\n",
    "     3  5.1  3.2   4.5\n",
    "\n",
    "and PC1 can be written as [0.05, 0.22, 0.97] in [A, B, C].\n",
    "Then you should return C, B as the two most important features.\n",
    "If scale is True, you should standardise the data first\n",
    "\n",
    "* :param df: pandas DataFrame\n",
    "* :param scale: boolean, whether to scale or not\n",
    "* :return: names of the two most important features as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C', 'B')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_most_important_two(df, scale):\n",
    "    df_new = get_coordinates_of_first_two(df, scale)\n",
    "    pc1 = abs(df_new.iloc[0])\n",
    "    feat_1 = pc1.idxmax()\n",
    "    drop_f1 = pc1.drop(feat_1)\n",
    "    feat_2 = drop_f1.idxmax()\n",
    "    most_import_features = tuple((feat_1, feat_2))\n",
    "    return most_import_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C', 'B')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample dataframe\n",
    "df = pd.DataFrame({'A': [1.3, 2.0, 3.3, 5.1], 'B': [1.2, 2.1, 6.8, 3.2], 'C': [0.1, 1.2, 23.4, 4.5]})\n",
    "scale = False\n",
    "get_most_important_two(df, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('flavanoids', 'total_phenols')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = True\n",
    "get_most_important_two(df_wine, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write a function that applies PCA on a given DataFrame df in order to find a new subspace of dimension n.\n",
    "\n",
    "Transform the two points point_a and point_b to be represented into that n dimensions space, compute the Euclidean distance between the points in that space and return it.\n",
    "\n",
    "Example: if the original DataFrame was:\n",
    "\n",
    "          A    B     C\n",
    "     0  1.3  1.2   0.1\n",
    "     1  2.0  2.1   1.2\n",
    "     2  3.3  6.8  23.4\n",
    "     3  5.1  3.2   4.5\n",
    "\n",
    "and n = 2, you can learn a new subspace with two columns [PC1, PC2].\n",
    "\n",
    "Then given two points:\n",
    "\n",
    "    point_a = [1, 2, 3]\n",
    "    point_b = [2, 3, 4]\n",
    "    expressed in [A, B, C]\n",
    "\n",
    "Transform them to be expressed in [PC1, PC2], here we would have:\n",
    "    \n",
    "    point_a -> [-4.57, -1.74]\n",
    "    point_b -> [-3.33, -0.65]\n",
    "\n",
    "and return the Euclidean distance between the points in that space.\n",
    "If scale is True, you should standardise the data first\n",
    "\n",
    "* :param df: pandas DataFrame\n",
    "* :param point_a: a numpy vector expressed in the same basis as df\n",
    "* :param point_b: a numpy vector expressed in the same basis as df\n",
    "* :param n: number of dimensions of the new space\n",
    "* :param scale: whether to scale data or not\n",
    "* :return: distance between points in the subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_in_n_dimensions(df, point_a, point_b, n, scale):\n",
    "    cols = df.columns\n",
    "    points = pd.DataFrame([point_a, point_b], columns=cols)\n",
    "    scaler = StandardScaler()\n",
    "    if scale:\n",
    "        scaler.fit(df)\n",
    "        df = pd.DataFrame(scaler.transform(df), columns=cols)\n",
    "        points = pd.DataFrame(scaler.transform(points), columns=cols)\n",
    "    pca = PCA(n_components=n)\n",
    "    fit_pca = pca.fit(df)\n",
    "    points_pca = fit_pca.transform(points)\n",
    "    dist_eucl = np.linalg.norm(points_pca[1] - points_pca[0])\n",
    "    return point_pca, dist_eucl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'point_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-a358790c5448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdistance_in_n_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-93-570ae9911a66>\u001b[0m in \u001b[0;36mdistance_in_n_dimensions\u001b[0;34m(df, point_a, point_b, n, scale)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpoints_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdist_eucl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpoints_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoint_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_eucl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'point_pca' is not defined"
     ]
    }
   ],
   "source": [
    "# sample dataframe\n",
    "df = pd.DataFrame({'A': [1.3, 2.0, 3.3, 5.1], 'B': [1.2, 2.1, 6.8, 3.2], 'C': [0.1, 1.2, 23.4, 4.5]})\n",
    "point_a = [1, 2, 3]\n",
    "point_b = [2, 3, 4]\n",
    "n=2\n",
    "scale = True\n",
    "distance_in_n_dimensions(df, point_a, point_b, n, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Apply PCA on a given DataFrame df and transofmr all the data to be expressed\n",
    "on the first principal component (you can discard other components)\n",
    "\n",
    "With all those points in a one-dimension space, find outliers by looking for points\n",
    "that lie at more than n standard deviations from the mean.\n",
    "\n",
    "You should return a new dataframe containing all the rows of the original dataset that have been found to be outliers when projected.\n",
    "\n",
    "Example:if the original DataFrame was:\n",
    "\n",
    "          A    B     C\n",
    "     0  1.3  1.2   0.1\n",
    "     1  2.0  2.1   1.2\n",
    "     2  3.3  6.8  23.4\n",
    "     3  5.1  3.2   4.5\n",
    "\n",
    "Once projected on PC1 it will be:\n",
    "    \n",
    "          PC1\n",
    "    0   -7.56\n",
    "    1   -6.26\n",
    "    2   16.46\n",
    "    3   -2.65\n",
    "\n",
    "Compute the mean of this one dimensional dataset and find all rows that lie at more than n standard deviations from it.\n",
    "\n",
    "Here, if n==1, only the row 2 is an outlier.\n",
    "\n",
    "So you should return:\n",
    "    \n",
    "         A    B     C\n",
    "    2  3.3  6.8  23.4\n",
    "\n",
    "If scale is True, you should standardise the data first\n",
    "Tip: use the StandardScaler from sklearn\n",
    "\n",
    "* :param df: pandas DataFrame\n",
    "* :param n: number of standard deviations from the mean to be considered outlier\n",
    "* :param scale: whether to scale data or not\n",
    "* :return: pandas DataFrame containing outliers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B     C\n",
       "2  3.3  6.8  23.4"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_outliers_pca(df, n, scale):\n",
    "    cols = df.columns\n",
    "    scaler = StandardScaler()\n",
    "    if scale:\n",
    "        df_new = pd.DataFrame(scaler.fit_transform(df), columns=cols)\n",
    "    else:\n",
    "        df_new = df.copy()\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(df)\n",
    "    points_new = pca.fit_transform(df_new)\n",
    "    a_mean_std = abs((points_new - points_new.mean())/points_new.std())\n",
    "    control = a_mean_std.reshape((a_mean_std.shape[0], ))\n",
    "    outliers = df[control > n]\n",
    "    return outliers\n",
    "\n",
    "df = pd.DataFrame({'A': {0: 1.3, 1: 2.0, 2: 3.3, 3: 5.1}, 'B': {0: 1.2, 1: 2.1, 2: 6.8, 3: 3.2},'C': {0: 0.1, 1: 1.2, 2: 23.4, 3: 4.5}})\n",
    "n = 1\n",
    "scale = False\n",
    "find_outliers_pca(df, n, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B     C\n",
       "2  3.3  6.8  23.4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or\n",
    "def find_outliers_pca(df, n, scale):\n",
    "    cols = df.columns\n",
    "    scaler = StandardScaler()\n",
    "    if scale:\n",
    "        df_new = pd.DataFrame(scaler.fit_transform(df),columns = cols)\n",
    "    else:\n",
    "        df_new = df.copy()\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(df)\n",
    "    points_new = pca.fit_transform(df_new)\n",
    "    a_mean_std = abs((points_new-points_new.mean())/points_new.std())\n",
    "    control = a_mean_std.reshape((a_mean_std.shape[0],))\n",
    "    outliers = df[control > n]\n",
    "    return outliers\n",
    "\n",
    "df = pd.DataFrame({'A': {0: 1.3, 1: 2.0, 2: 3.3, 3: 5.1}, 'B': {0: 1.2, 1: 2.1, 2: 6.8, 3: 3.2},'C': {0: 0.1, 1: 1.2, 2: 23.4, 3: 4.5}})\n",
    "n = 1\n",
    "scale = False\n",
    "find_outliers_pca(df, n, scale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (capstone)",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
